{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPAYK9upRe26"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdYdVtWYRUcV"
      },
      "source": [
        "import torch\n",
        "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Encode a text inputs\n",
        "text = \"I hope\"\n",
        "predicted_text = text\n",
        "while predicted_text[-1] not in {'.','?','!','~','\\n'}:\n",
        "    text = predicted_text\n",
        "    indexed_tokens = tokenizer.encode(text)\n",
        "    # Convert indexed tokens in a PyTorch tensor\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    # Load pre-trained model (weights)\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    # Set the model in evaluation mode to deactivate the DropOut modules\n",
        "    model.eval()\n",
        "\n",
        "    # Predict all tokens\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens_tensor)\n",
        "        predictions = outputs[0]\n",
        "\n",
        "    # Get the predicted next sub-word\n",
        "    predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
        "    predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
        "    print(predicted_text)\n",
        "\n",
        "# Print the predicted word\n",
        "print(predicted_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgKNJnMQktpg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}